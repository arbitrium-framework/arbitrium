# Arbitrium Framework - Example Configuration
# This is the default configuration for heterogeneous tournaments with diverse models

# Question to analyze (can also be provided via CLI argument)
question: >
  Put your question here.

# Model configurations for heterogeneous tournament
models:
  gpt: {}
  claude: {}
  gemini: {}
  grok: {}

  # Optional: Add more models for larger tournaments
  # grok:
  #   provider: xai
  #   model_name: xai/grok-2
  #   display_name: "Grok 2"
  #   temperature: 0.8
  #   max_tokens: 4096

# Tournament configuration
tournament:
  # Judge model for scoring responses (can be one of the tournament models or separate)
  judge_model: claude  # Use Claude as the judge
  # Number of improvement rounds before elimination
  improvement_rounds: 2
  # Anonymize model identities during evaluation (recommended for fairness)
  anonymize: true
# Knowledge Bank configuration
knowledge_bank:
  enabled: true
  # Maximum number of insights to preserve from each eliminated model
  max_insights: 5
  # Similarity threshold for deduplication (0.0-1.0, higher = more strict)
  similarity_threshold: 0.85
  # Model to use for extracting insights from eliminated models
  extraction_model: claude

# Output configuration
outputs_dir: "."

# Logging
logging:
  level: INFO
  file_logging: true
  console_logging: true

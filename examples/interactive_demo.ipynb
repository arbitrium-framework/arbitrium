{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# üèÜ Arbitrium Framework - Interactive Browser Demo\n\n## Tournament-Based AI Decision Synthesis - Live in Your Browser!\n\nWelcome! This interactive notebook lets you run **real** Arbitrium tournaments with **actual AI models** right here in your browser.\n\n**What you'll experience:**\n- ü§ñ Real AI models (GPT-4, Claude, Grok) competing on your question\n- üîÑ Live tournament execution with real API calls\n- ‚öîÔ∏è Competitive elimination rounds\n- üß† Knowledge Bank preserving insights from eliminated models\n- ü•á Champion solution synthesizing the best ideas\n- üí∞ Real cost tracking and metrics\n\n**Requirements:**\n- Your own API keys (OpenAI, Anthropic, or XAI)\n- ~$0.50-2.00 per tournament (depending on models used)\n- 5-10 minutes runtime\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Arbitrium Framework\n",
    "\n",
    "First, let's install the framework. In Pyodide/JupyterLite environments, use `micropip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Step 1: Install Arbitrium Framework\n",
    "\n",
    "# This cell installs the Arbitrium Framework directly from its\n",
    "# GitHub repository. This ensures you're always using the most\n",
    "# up-to-date version for this demo.\n",
    "# The -q (--quiet) flag is used to reduce the installation output.\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "print(\"üì¶ Checking for and installing Arbitrium Framework...\")\n",
    "\n",
    "try:\n",
    "    # Attempt to import the package\n",
    "    importlib.import_module(\"arbitrium\")\n",
    "    print(\"‚úÖ Arbitrium Framework is already installed.\")\n",
    "except ImportError:\n",
    "    # If the import fails, install from GitHub\n",
    "    print(\"   -> Package not found. Installing from GitHub...\")\n",
    "    try:\n",
    "        # Use subprocess for more reliable execution\n",
    "        install_command = [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"-q\",\n",
    "            \"git+https://github.com/arbitrium-framework/arbitrium.git\",\n",
    "        ]\n",
    "        result = subprocess.run(\n",
    "            install_command,\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "        )\n",
    "        print(\"   -> Installation complete.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"\\n‚ùå INSTALLATION ERROR:\")\n",
    "        print(\"Failed to install the package from GitHub.\")\n",
    "        print(f\"Stderr: {e.stderr}\")\n",
    "        raise e\n",
    "\n",
    "# Try to import again after installation\n",
    "try:\n",
    "    import arbitrium\n",
    "\n",
    "    version = arbitrium.__version__\n",
    "    print(\n",
    "        f\"\\nüéâ Arbitrium Framework v{version} imported \"\n",
    "        f\"successfully and is ready to go!\"\n",
    "    )\n",
    "except ImportError as e:\n",
    "    print(\"\\n‚ùå CRITICAL ERROR:\")\n",
    "    print(\n",
    "        \"Even after a successful installation, the package \"\n",
    "        \"could not be imported. This can sometimes happen \"\n",
    "        \"in Colab environments.\"\n",
    "    )\n",
    "    print(\n",
    "        \"Please restart the runtime (from the menu: Runtime -> \"\n",
    "        \"Restart runtime) and run the cells again.\"\n",
    "    )\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure Your API Keys\n",
    "\n",
    "**Security Note:** Your API keys stay in your browser session and are never sent anywhere except directly to the AI providers.\n",
    "\n",
    "Choose which models you want to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Step 2: Configure Your API Keys\n",
    "# @markdown **Security Note:** Your API keys are never saved\n",
    "# @markdown in this notebook. They are only stored in memory for\n",
    "# @markdown this session.\n",
    "# @markdown\n",
    "# @markdown **Option 1:** Use Google Colab Secrets (recommended)\n",
    "# @markdown **Option 2:** Enter keys manually (hidden as you type)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"üîê API Key Configuration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if we're in Google Colab\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "\n",
    "    IN_COLAB = True\n",
    "    print(\"‚úì Running in Google Colab - checking for secrets...\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"‚úì Running in standard Jupyter environment\")\n",
    "\n",
    "print()\n",
    "\n",
    "# API key configuration\n",
    "api_keys_config = {\n",
    "    \"OPENAI_API_KEY\": {\n",
    "        \"name\": \"OpenAI\",\n",
    "        \"colab_secret\": \"OPENAI_API_KEY\",\n",
    "        \"url\": \"https://platform.openai.com/api-keys\",\n",
    "    },\n",
    "    \"ANTHROPIC_API_KEY\": {\n",
    "        \"name\": \"Anthropic\",\n",
    "        \"colab_secret\": \"ANTHROPIC_API_KEY\",\n",
    "        \"url\": \"https://console.anthropic.com/settings/keys\",\n",
    "    },\n",
    "    \"XAI_API_KEY\": {\n",
    "        \"name\": \"XAI (Grok)\",\n",
    "        \"colab_secret\": \"XAI_API_KEY\",\n",
    "        \"url\": \"https://console.x.ai/\",\n",
    "    },\n",
    "}\n",
    "\n",
    "configured_keys = 0\n",
    "\n",
    "# Try to load from Google Colab secrets first\n",
    "if IN_COLAB:\n",
    "    print(\"üìã Checking Google Colab Secrets...\")\n",
    "    for env_var, config in api_keys_config.items():\n",
    "        try:\n",
    "            secret_value = userdata.get(config[\"colab_secret\"])\n",
    "            if secret_value:\n",
    "                os.environ[env_var] = secret_value\n",
    "                print(\n",
    "                    f\"  ‚úÖ {config['name']:15} loaded from \"\n",
    "                    f\"Colab secrets\"\n",
    "                )\n",
    "                configured_keys += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "    print()\n",
    "\n",
    "# If not in Colab or keys not found, prompt for manual entry\n",
    "if configured_keys == 0:\n",
    "    print(\n",
    "        \"‚å®Ô∏è  Manual Entry Mode \"\n",
    "        \"(keys will be hidden as you type)\"\n",
    "    )\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Press Enter to skip a key if you don't have it.\")\n",
    "    print(\"You need at least 2 keys to run a tournament.\\n\")\n",
    "\n",
    "    import getpass\n",
    "\n",
    "    for env_var, config in api_keys_config.items():\n",
    "        # Check if already set in environment\n",
    "        if os.getenv(env_var):\n",
    "            print(\n",
    "                f\"  ‚úÖ {config['name']:15} already set \"\n",
    "                f\"in environment\"\n",
    "            )\n",
    "            configured_keys += 1\n",
    "            continue\n",
    "\n",
    "        # Prompt for key\n",
    "        try:\n",
    "            key_value = getpass.getpass(\n",
    "                f\"  {config['name']:15} API key \"\n",
    "                f\"(or Enter to skip): \"\n",
    "            )\n",
    "            if key_value and key_value.strip():\n",
    "                os.environ[env_var] = key_value.strip()\n",
    "                print(f\"  ‚úÖ {config['name']:15} configured\")\n",
    "                configured_keys += 1\n",
    "            else:\n",
    "                print(f\"  ‚è≠Ô∏è  {config['name']:15} skipped\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error reading {config['name']} key: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Provide feedback\n",
    "if configured_keys >= 2:\n",
    "    print(\n",
    "        f\"‚úÖ Configuration complete! {configured_keys} \"\n",
    "        f\"API key(s) are set.\"\n",
    "    )\n",
    "    print(\n",
    "        \"\\nüí° Your keys are stored only in memory and will \"\n",
    "        \"not be saved in this notebook.\"\n",
    "    )\n",
    "elif configured_keys == 1:\n",
    "    print(f\"‚ö†Ô∏è  WARNING: Only {configured_keys} key configured.\")\n",
    "    print(\"   A tournament requires at least 2 keys.\")\n",
    "    print(\"\\n   Re-run this cell to add more keys.\")\n",
    "    print(\"\\nüîë Get API keys here:\")\n",
    "    for config in api_keys_config.values():\n",
    "        print(f\"   ‚Ä¢ {config['name']:15} {config['url']}\")\n",
    "else:\n",
    "    print(\"‚ùå No API keys configured!\")\n",
    "    print(\"\\nüîë Get API keys here:\")\n",
    "    for config in api_keys_config.values():\n",
    "        print(f\"   ‚Ä¢ {config['name']:15} {config['url']}\")\n",
    "    print(\"\\nüí° For Google Colab users:\")\n",
    "    print(\"   1. Click the üîë icon in the left sidebar\")\n",
    "    print(\n",
    "        \"   2. Add secrets with these names: OPENAI_API_KEY, \"\n",
    "        \"ANTHROPIC_API_KEY, etc.\"\n",
    "    )\n",
    "    print(\"   3. Enable 'Notebook access' for each secret\")\n",
    "    print(\"   4. Re-run this cell\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Tournament Configuration\n",
    "\n",
    "Let's build a configuration dynamically based on which API keys you provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Build model configuration based on available API keys\n",
    "models_config = {}\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    models_config[\"gpt\"] = {\n",
    "        \"provider\": \"openai\",\n",
    "        \"model_name\": \"gpt-5\",\n",
    "        \"display_name\": \"GPT-5\",\n",
    "        \"temperature\": 1.0,  # GPT-5 requires temperature=1.0\n",
    "        \"context_window\": 128000,  # 128k context window\n",
    "        \"max_tokens\": 16384,  # Max output tokens\n",
    "    }\n",
    "\n",
    "if os.getenv(\"ANTHROPIC_API_KEY\"):\n",
    "    models_config[\"claude\"] = {\n",
    "        \"provider\": \"anthropic\",\n",
    "        \"model_name\": \"claude-sonnet-4-5-20250929\",\n",
    "        \"display_name\": \"Claude 4.5 Sonnet\",\n",
    "        \"temperature\": 1.0,\n",
    "        \"context_window\": 200000,  # 200k context window\n",
    "        \"max_tokens\": 8192,  # Max output tokens\n",
    "    }\n",
    "\n",
    "if os.getenv(\"XAI_API_KEY\"):\n",
    "    models_config[\"grok\"] = {\n",
    "        \"provider\": \"xai\",\n",
    "        \"model_name\": \"xai/grok-4-latest\",\n",
    "        \"display_name\": \"Grok 4\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"context_window\": 131072,  # 128k context window\n",
    "        \"max_tokens\": 16384,  # Max output tokens\n",
    "    }\n",
    "\n",
    "# ‚ö†Ô∏è VALIDATION: Check for sufficient models\n",
    "if not models_config:\n",
    "    raise ValueError(\n",
    "        \"‚ùå No API keys configured! Please run Step 2 and \"\n",
    "        \"provide at least one API key.\"\n",
    "    )\n",
    "\n",
    "if len(models_config) < 2:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: INSUFFICIENT MODELS FOR TOURNAMENT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\n",
    "        f\"\\n‚ùå Found only {len(models_config)} active model(s):\"\n",
    "    )\n",
    "    for _key, model in models_config.items():\n",
    "        print(f\"   ‚Ä¢ {model['display_name']}\")\n",
    "    print(\n",
    "        \"\\nüèÜ Arbitrium tournaments require at least 2 models \"\n",
    "        \"to compete.\"\n",
    "    )\n",
    "    print(\"\\nüí° To fix this:\")\n",
    "    print(\"   1. ‚¨ÜÔ∏è  Scroll up to Step 2\")\n",
    "    print(\n",
    "        \"   2. Re-run that cell and enter at least one more \"\n",
    "        \"API key\"\n",
    "    )\n",
    "    print(\"   3. Then come back and re-run Steps 3-6\")\n",
    "    print(\"\\nüîë Need API keys? Get them here:\")\n",
    "    print(\"   ‚Ä¢ OpenAI:    https://platform.openai.com/api-keys\")\n",
    "    print(\n",
    "        \"   ‚Ä¢ Anthropic: \"\n",
    "        \"https://console.anthropic.com/settings/keys\"\n",
    "    )\n",
    "    print(\"   ‚Ä¢ XAI:       https://console.x.ai/\")\n",
    "    print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "    raise ValueError(\n",
    "        f\"Tournament requires 2+ models, but only \"\n",
    "        f\"{len(models_config)} configured. \"\n",
    "        \"Please add more API keys in Step 2.\"\n",
    "    )\n",
    "\n",
    "# Create output directory in current location\n",
    "output_dir = Path(\"./arbitrium_demo_outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "temp_dir = str(output_dir)\n",
    "\n",
    "# Minimal configuration - prompts, retry, features will use defaults\n",
    "config = {\n",
    "    \"models\": models_config,\n",
    "    \"outputs_dir\": temp_dir,\n",
    "}\n",
    "\n",
    "print(\"üéØ Tournament Configuration\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìä Active Models ({len(models_config)}):\")\n",
    "for _key, model in models_config.items():\n",
    "    print(f\"  ‚Ä¢ {model['display_name']} ({model['model_name']})\")\n",
    "\n",
    "print(f\"\\nüìÅ Output Directory: {temp_dir}\")\n",
    "print(\n",
    "    \"\\nüí° Using default framework settings for prompts, \"\n",
    "    \"retry, and features\"\n",
    ")\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize Arbitrium Framework\n",
    "\n",
    "Now let's initialize the framework and perform health checks on all models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arbitrium import Arbitrium\n",
    "\n",
    "print(\"üèÅ Initializing Arbitrium Framework...\\n\")\n",
    "\n",
    "# Initialize from settings\n",
    "arbitrium = await Arbitrium.from_settings(\n",
    "    settings=config,\n",
    "    skip_secrets=True,  # We already set environment variables\n",
    "    skip_health_check=False,  # DO perform health checks\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä Model Health Check Results\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Healthy Models: {arbitrium.healthy_model_count}\")\n",
    "if arbitrium.healthy_model_count > 0:\n",
    "    for model_key in arbitrium.healthy_models.keys():\n",
    "        model = arbitrium.healthy_models[model_key]\n",
    "        print(f\"   ‚Ä¢ {model.full_display_name}\")\n",
    "\n",
    "if arbitrium.failed_model_count > 0:\n",
    "    print(f\"\\n‚ùå Failed Models: {arbitrium.failed_model_count}\")\n",
    "    for model_key, error in arbitrium.failed_models.items():\n",
    "        print(f\"   ‚Ä¢ {model_key}: {error}\")\n",
    "    print(\"\\n‚ö†Ô∏è  Continuing with healthy models only.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "if arbitrium.healthy_model_count < 2:\n",
    "    raise ValueError(\n",
    "        \"‚ùå Need at least 2 healthy models to run a tournament! \"\n",
    "        \"Please check your API keys and try again.\"\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"üéâ Ready to run tournament with \"\n",
    "    f\"{arbitrium.healthy_model_count} models!\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define Your Strategic Question\n",
    "\n",
    "Choose a question for the tournament. This should be a high-stakes, complex decision where multiple perspectives add value.\n",
    "\n",
    "**Examples:**\n",
    "- Strategic business decisions\n",
    "- Technical architecture choices\n",
    "- Market analysis and positioning\n",
    "- Product roadmap prioritization\n",
    "\n",
    "**Edit the question below or use the example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your question here\n",
    "question = \"\"\"\n",
    "What are the best precommit hooks that every repo should use?\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"‚ùì Tournament Question\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{question}\\n\")\n",
    "print(\"=\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run the Tournament! üèÜ\n",
    "\n",
    "This will execute the full tournament:\n",
    "1. **Phase 1**: Each model generates independent initial responses\n",
    "2. **Phase 2**: Models improve based on peer feedback\n",
    "3. **Phase 3**: Cross-evaluation and elimination\n",
    "4. **Repeat**: Until one champion remains\n",
    "\n",
    "**Expected runtime:** 5-10 minutes (depending on number of models)\n",
    "\n",
    "**Expected cost:** $0.50-$2.00 (you'll see exact costs below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèÜ ARBITRIUM TOURNAMENT - LIVE EXECUTION\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run the tournament with REAL API calls\n",
    "result, metrics = await arbitrium.run_tournament(question)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèÅ TOURNAMENT COMPLETE\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "print(\n",
    "    f\"‚è±Ô∏è  Duration: {duration:.1f} seconds \"\n",
    "    f\"({duration/60:.1f} minutes)\"\n",
    ")\n",
    "print(f\"üí∞ Total Cost: ${metrics['total_cost']:.4f}\")\n",
    "print(f\"ü•á Champion: {metrics['champion_model']}\")\n",
    "print(\n",
    "    f\"üóëÔ∏è  Eliminated: {len(metrics['eliminated_models'])} \"\n",
    "    f\"models\"\n",
    ")\n",
    "\n",
    "if metrics[\"eliminated_models\"]:\n",
    "    print(\"\\n   Elimination order:\")\n",
    "    for i, model in enumerate(metrics[\"eliminated_models\"], 1):\n",
    "        print(f\"   {i}. {model}\")\n",
    "\n",
    "print(\"\\nüí∏ Cost Breakdown:\")\n",
    "for model, cost in sorted(\n",
    "    metrics[\"cost_by_model\"].items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True,\n",
    "):\n",
    "    pct = (\n",
    "        (cost / metrics[\"total_cost\"] * 100)\n",
    "        if metrics[\"total_cost\"] > 0\n",
    "        else 0\n",
    "    )\n",
    "    print(f\"   {model:20} ${cost:7.4f} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: View Champion Solution\n",
    "\n",
    "Here's the winning answer that synthesizes insights from all competing models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìú CHAMPION SOLUTION\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "display(Markdown(result))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Download Tournament Reports\n",
    "\n",
    "Arbitrium Framework generates detailed reports. In Google Colab, files will be auto-downloaded to your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "print(\"üìÅ Tournament Reports\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Find generated reports\n",
    "report_files = glob.glob(\n",
    "    f\"{temp_dir}/arbitrium_*.json\"\n",
    ") + glob.glob(f\"{temp_dir}/arbitrium_*.md\")\n",
    "\n",
    "if report_files:\n",
    "    print(f\"‚úÖ Generated {len(report_files)} report files:\\n\")\n",
    "    for filepath in sorted(report_files):\n",
    "        filename = Path(filepath).name\n",
    "        size_kb = Path(filepath).stat().st_size / 1024\n",
    "        print(f\"   üìÑ {filename} ({size_kb:.1f} KB)\")\n",
    "\n",
    "    print(f\"\\nüìÇ Location: {temp_dir}\")\n",
    "    print(\"\\nüí° Tip: These files contain:\")\n",
    "    print(\n",
    "        \"   ‚Ä¢ Complete tournament history \"\n",
    "        \"(all responses, scores)\"\n",
    "    )\n",
    "    print(\"   ‚Ä¢ Provenance tracking (how ideas evolved)\")\n",
    "    print(\"   ‚Ä¢ Knowledge Bank insights\")\n",
    "    print(\"   ‚Ä¢ Cost breakdown by phase\")\n",
    "\n",
    "    # Auto-download in Google Colab\n",
    "    if IN_COLAB:\n",
    "        print(\"\\nüì• Downloading files to your computer...\")\n",
    "        try:\n",
    "            from google.colab import files\n",
    "\n",
    "            for filepath in sorted(report_files):\n",
    "                filename = Path(filepath).name\n",
    "                print(f\"   ‚¨áÔ∏è  {filename}\")\n",
    "                files.download(filepath)\n",
    "            print(\"\\n‚úÖ All files downloaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è  Could not auto-download: {e}\")\n",
    "            print(\n",
    "                \"   You can manually download files from the \"\n",
    "                \"Files panel (üìÅ icon in left sidebar)\"\n",
    "            )\n",
    "    else:\n",
    "        print(\n",
    "            f\"\\nüíæ Files saved locally at: \"\n",
    "            f\"{Path(temp_dir).absolute()}\"\n",
    "        )\n",
    "else:\n",
    "    print(\n",
    "        \"‚ö†Ô∏è  No report files found \"\n",
    "        \"(may be disabled in config)\"\n",
    "    )\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Compare with Single Model (Optional)\n",
    "\n",
    "Want to see how the tournament compares to just asking one model? Let's run the same question through a single model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose first healthy model for comparison\n",
    "comparison_model_key = next(iter(arbitrium.healthy_models.keys()))\n",
    "comparison_model = arbitrium.healthy_models[comparison_model_key]\n",
    "\n",
    "print(\n",
    "    f\"ü§ñ Running single model comparison: \"\n",
    "    f\"{comparison_model.full_display_name}\\n\"\n",
    ")\n",
    "\n",
    "single_response = await arbitrium.run_single_model(\n",
    "    comparison_model_key, question\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\n",
    "    f\"üìù SINGLE MODEL RESPONSE \"\n",
    "    f\"({comparison_model.full_display_name})\"\n",
    ")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "display(Markdown(single_response.content))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚öñÔ∏è  COMPARISON\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "print(f\"Tournament Champion: {metrics['champion_model']}\")\n",
    "print(f\"Tournament Cost: ${metrics['total_cost']:.4f}\")\n",
    "print(f\"Tournament Time: {duration:.1f}s\")\n",
    "print(\n",
    "    f\"\\nSingle Model: {comparison_model.full_display_name}\"\n",
    ")\n",
    "print(f\"Single Model Cost: ${single_response.cost:.4f}\")\n",
    "print(\n",
    "    f\"\\nüí∞ Cost Multiplier: \"\n",
    "    f\"{metrics['total_cost'] / single_response.cost:.1f}x\"\n",
    ")\n",
    "print(\n",
    "    \"\\nüí° Analysis: Is the tournament answer worth \"\n",
    "    \"the extra cost?\"\n",
    ")\n",
    "print(\"   Read both answers above and decide!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Try Your Own Question!\n",
    "\n",
    "Now that you've seen it work, modify the question in Step 5 and run Steps 6-9 again with your own strategic problem.\n",
    "\n",
    "**Tips for good tournament questions:**\n",
    "- Complex with multiple valid approaches\n",
    "- High-stakes ($5,000+ impact)\n",
    "- Benefits from diverse perspectives\n",
    "- Has context and constraints\n",
    "- No single \"obviously correct\" answer\n",
    "\n",
    "**Poor tournament questions:**\n",
    "- Simple factual queries\n",
    "- Questions with objective right answers\n",
    "- Very broad without constraints\n",
    "- Low-stakes decisions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: What You Just Experienced\n",
    "\n",
    "### üéâ Congratulations!\n",
    "\n",
    "You just ran a **real Arbitrium Framework tournament** with actual AI models:\n",
    "\n",
    "1. ‚úÖ **Multiple AI models competed** with real API calls\n",
    "2. ‚úÖ **Competitive pressure** drove higher quality responses\n",
    "3. ‚úÖ **Knowledge Bank preserved** insights from eliminated models\n",
    "4. ‚úÖ **Champion solution synthesized** the best ideas from all perspectives\n",
    "5. ‚úÖ **Full traceability** with downloadable reports\n",
    "6. ‚úÖ **Cost tracking** showed exactly what you spent\n",
    "\n",
    "### üìä Tournament vs. Single Model\n",
    "\n",
    "**When Tournament Wins:**\n",
    "- Multiple valid approaches to explore\n",
    "- High stakes justify the cost\n",
    "- Need defensible audit trail\n",
    "- Synthesis of diverse viewpoints matters\n",
    "\n",
    "**When Single Model is Fine:**\n",
    "- Simple queries\n",
    "- Time-sensitive decisions\n",
    "- Low-stakes problems\n",
    "- Budget constraints\n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "**Use Arbitrium Locally:**\n",
    "```bash\n",
    "pip install arbitrium-framework\n",
    "cp config.example.yml config.yml\n",
    "# Edit config.yml with your API keys\n",
    "arbitrium  # Run CLI\n",
    "```\n",
    "\n",
    "**Programmatic Usage:**\n",
    "```python\n",
    "from arbitrium import Arbitrium\n",
    "\n",
    "arbitrium = await Arbitrium.from_config(\"config.yml\")\n",
    "result, metrics = await arbitrium.run_tournament(\"Your question\")\n",
    "```\n",
    "\n",
    "**Learn More:**\n",
    "- üìñ [Documentation](https://github.com/arbitrium-framework/arbitrium)\n",
    "- üéØ [More Examples](https://github.com/arbitrium-framework/arbitrium/tree/main/examples)\n",
    "- üí¨ [Discord Community](https://discord.gg/arbitrium)\n",
    "- üêõ [Report Issues](https://github.com/arbitrium-framework/arbitrium/issues)\n",
    "\n",
    "### üí° Key Takeaways\n",
    "\n",
    "1. **Competitive synthesis works**: Tournament pressure + Knowledge Bank preservation = better outcomes\n",
    "2. **Real cost tracking**: Always know what you're spending\n",
    "3. **Full auditability**: Every decision is traceable\n",
    "4. **Model-agnostic**: Use any combination of OpenAI, Anthropic, Google, etc.\n",
    "5. **Right tool for the job**: Use tournaments for high-stakes decisions, single models for everything else\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for trying Arbitrium Framework!**\n",
    "\n",
    "If this helped solve a real decision for you, consider:\n",
    "- ‚≠ê Starring the [GitHub repo](https://github.com/arbitrium-framework/arbitrium)\n",
    "- üì¢ Sharing your results (with permission)\n",
    "- ü§ù Contributing improvements\n",
    "\n",
    "*Arbitrium Framework‚Ñ¢ - Tournament-Based AI Decision Synthesis*\n",
    "\n",
    "*MIT License | Not affiliated with Arbitrum or Arbitrium RAT*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
